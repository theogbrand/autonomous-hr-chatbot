{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OAI Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../creds/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_endpoint = \"https://cursor-gpt-4.openai.azure.com\"\n",
    "api_version=\"2024-02-15-preview\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        api_version=api_version,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THREE types of tools: Code Interpreter, Retrieval, Function Calling\n",
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8vFihbxIPrB8ib9zfd69rt870LoiJ', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L8SgNpYAuYUI3LzPQiG307GF', function=Function(arguments='{\"location\":\"Seattle\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')]), content_filter_results={})], created=1708655815, model='gpt-35-turbo', object='chat.completion', system_fingerprint='fp_68a7d165bf', usage=CompletionUsage(completion_tokens=20, prompt_tokens=105, total_tokens=125), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like today in Seattle?\"}\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"pjf-dpo-turbo-35\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, or none\n",
    ")\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "Always look things up on Wikipedia if you have the opportunity to do so.\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the capital of France?\n",
    "Thought: I should look up France on Wikipedia\n",
    "Action: wikipedia: France\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: France is a country. The capital is Paris.\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: The capital of France is Paris\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        # deployment_name = \"cursor-gpt-4\"\n",
    "        deployment_name = \"pjf-dpo-turbo-35\"\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,  # e.g. gpt-35-instant\n",
    "            messages=self.messages,\n",
    "            # tools=functions,\n",
    "        )\n",
    "        # Uncomment this to print out token usage each time, e.g.\n",
    "        # {\"completion_tokens\": 86, \"prompt_tokens\": 26, \"total_tokens\": 112}\n",
    "        # print(completion.usage)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wikipedia(q):\n",
    "#     return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
    "#         \"action\": \"query\",\n",
    "#         \"list\": \"search\",\n",
    "#         \"srsearch\": q,\n",
    "#         \"format\": \"json\"\n",
    "#     }).json()[\"query\"][\"search\"][0][\"snippet\"]\n",
    "\n",
    "\n",
    "# def simon_blog_search(q):\n",
    "#     results = httpx.get(\"https://datasette.simonwillison.net/simonwillisonblog.json\", params={\n",
    "#         \"sql\": \"\"\"\n",
    "#         select\n",
    "#           blog_entry.title || ': ' || substr(html_strip_tags(blog_entry.body), 0, 1000) as text,\n",
    "#           blog_entry.created\n",
    "#         from\n",
    "#           blog_entry join blog_entry_fts on blog_entry.rowid = blog_entry_fts.rowid\n",
    "#         where\n",
    "#           blog_entry_fts match escape_fts(:q)\n",
    "#         order by\n",
    "#           blog_entry_fts.rank\n",
    "#         limit\n",
    "#           1\"\"\".strip(),\n",
    "#         \"_shape\": \"array\",\n",
    "#         \"q\": q,\n",
    "#     }).json()\n",
    "#     return results[0][\"text\"]\n",
    "\n",
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "known_actions = {\n",
    "    # \"wikipedia\": wikipedia,\n",
    "    \"calculate\": calculate,\n",
    "    # \"simon_blog_search\": simon_blog_search\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')\n",
    "# action_input_regex = re.compile('^Action Input: (\\w+): (.*)$')\n",
    "\n",
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(react_prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
    "        print(\"Actions Retrieved\", actions)\n",
    "        # action_inputs = [action_input_regex.match(a) for a in result.split('\\n') if action_input_regex.match(a)]\n",
    "        # print(\"Action Inputs\", action_inputs)\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what is 2 * twenty five\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* ask user for clarification after single ReAct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
